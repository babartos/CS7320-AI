{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Vacuum-cleaner World\n",
    "Matthew Bartos\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: 10\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with \n",
    "\n",
    "* your implementation,\n",
    "* documentation including a short discussion of how your implementation works and your design choices, and\n",
    "* experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. \n",
    "\n",
    "Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment you will implement a simulator environment for an automatic vacuum cleaner robot, a set of different agent programs, and perform a comparison study for cleaning a single room. Focus on the __cleaning phase__ which starts when the robot is activated and ends when the last dirty square is cleaned. Someone else will take care of the agent program needed to navigate back to the charging station after the room is clean.\n",
    "\n",
    "## PEAS description of the cleaning phase\n",
    "\n",
    "__Performance Measure:__ Each action costs 1 energy unit. The performance is measured as the sum of the energy units used to clean the whole room.\n",
    "\n",
    "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size and the layout of the room (i.e., it knows $n$). To starte, the agent is placed on a random square.\n",
    "\n",
    "__Actuators:__ The agent can `clean` the current square or move to an adjacent square by going `north`, `east`, `south`, or `west`.\n",
    "\n",
    "__Sensors:__ Four bumper sensors, one for north, east, south, and west; a dirt sensor reporting dirt in the current square.  \n",
    "\n",
    "\n",
    "## The agent program for a simple randomized agent\n",
    "\n",
    "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
    "\n",
    "* A dictionary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`. E.g., if the agent is on the north-west corner, `bumpers` will be `{\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}`.\n",
    "* The dirt sensor produces a boolean.\n",
    "\n",
    "The agent returns the chosen action as a string.\n",
    "\n",
    "Here is an example implementation for the agent program of a simple randomized agent:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "\n",
    "\n",
    "def simple_randomized_agent(bumpers, dirty):\n",
    "    return random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'west'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_randomized_agent({\"north\" : True, \"east\" : False, \"south\" : False, \"west\" : True}, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ This is not a rational intelligent agent. It ignores its sensors and may bump into a wall or not clean a dirty square. You will be asked to implement rational agents below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple environment example\n",
    "\n",
    "This simple environment is infinite in size (bumpers are always `False`) and every square is always dirty, even if the agent cleans it. The environment function returns the performance measure which is here the number of cleaned squares (since all squares are constantly dirty, it is the number of `suck` actions by the agent). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_environment(agent, max_steps, verbose = True):\n",
    "    num_cleaned = 0\n",
    "    \n",
    "    for i in range(max_steps):\n",
    "        dirty = True\n",
    "        bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action) \n",
    "        \n",
    "        if (action == \"suck\"): \n",
    "            num_cleaned = num_cleaned + 1\n",
    "        \n",
    "    return num_cleaned\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do one simulation run with 20 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 - action: south\n",
      "step 1 - action: east\n",
      "step 2 - action: north\n",
      "step 3 - action: east\n",
      "step 4 - action: east\n",
      "step 5 - action: west\n",
      "step 6 - action: suck\n",
      "step 7 - action: north\n",
      "step 8 - action: east\n",
      "step 9 - action: suck\n",
      "step 10 - action: east\n",
      "step 11 - action: north\n",
      "step 12 - action: north\n",
      "step 13 - action: west\n",
      "step 14 - action: suck\n",
      "step 15 - action: south\n",
      "step 16 - action: south\n",
      "step 17 - action: suck\n",
      "step 18 - action: south\n",
      "step 19 - action: west\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_environment(simple_randomized_agent, max_steps = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "_Submission Instructions:_ Use this notebook to prepare your submission. Complete this section with your code and results. You can add additional Markdown blocks for your description, comments in the code and use mathplotlib to produce charts. \n",
    "\n",
    "_Note:_ Try to keep the code simple! In this course, we want to learn about the algorithms and we often do not need to use object-oriented design. \n",
    "\n",
    "\n",
    "## Task 1: Implement a simulation environment [2 Points]\n",
    "\n",
    "The simple environment above is not very realistic. Your environment simulator needs to follow the PEAS description from above. It needs to:\n",
    "\n",
    "* Initialize the environment by storing the state of each square (clean/dirty) and making some dirty.\n",
    "* Keep track of the agent's position.\n",
    "* Call the agent function repeatedly and provide the agent function with the sensor inputs.  \n",
    "* React to the agent's actions. E.g, by removing dirt from a square or moving the agent around unless there is a wall in the way.\n",
    "* Keep track of the performance measure. That is, track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
    "\n",
    "The easiest implementation for the environment is to hold an 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop until all squares are clean or a predefined number of steps have been reached (i.e., the robot runs out of energy).\n",
    "\n",
    "The simulation environment needs to work with the simple randomized agent program from above and then it can be used for your agent implementation in the tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the environment\n",
    "n = 5 #size\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "for i in range(n):\n",
    "    myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    \n",
    "myMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#globally define the bumpers\n",
    "bumpers = {\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}\n",
    "\n",
    "def simulation_environment(agent, max_steps, verbose = False):\n",
    "    # Performance: keep track of energy units. Each energy movement costs 1:\n",
    "    PerformanceMeasure = 0\n",
    "    # Keep track of the agent's position:\n",
    "    xPos = 0 # moving north is -1, moving south is +1\n",
    "    yPos = 0 # moving east is +1, moving west is -1\n",
    "    num_cleaned = 0\n",
    "    \n",
    "    #Iterate through the map\n",
    "    for i in range(max_steps):\n",
    "        dirty = False \n",
    "        if myMap[xPos, yPos] == 0:\n",
    "            dirty = True\n",
    "            \n",
    "\n",
    "        action = agent(bumpers, dirty)\n",
    "        if (verbose): print(\"step\", i , \"- action:\", action) \n",
    "        #react to the agents actions\n",
    "        \n",
    "        if (action == \"suck\"):\n",
    "            myMap[xPos, yPos] = 1 #the \n",
    "            num_cleaned = num_cleaned + 1\n",
    "        #if direction equals north\n",
    "        if (action == \"north\"):\n",
    "            xPos = xPos - 1\n",
    "            if xPos < 0: \n",
    "                xPos = 0\n",
    "        #if direction equals south\n",
    "        if (action == \"south\"):\n",
    "            xPos = xPos + 1\n",
    "            if xPos == (n-1):\n",
    "                bumpers[\"south\"] = True\n",
    "            if xPos > (n-1): #if wall\n",
    "                xPos = (n-1)\n",
    "         #if direction equals east       \n",
    "        if (action == \"east\"):\n",
    "            yPos = yPos + 1\n",
    "            if yPos > (n-1): \n",
    "                yPos = (n-1)\n",
    "        #if direction equals west\n",
    "        if (action == \"west\"):\n",
    "            yPos = yPos - 1\n",
    "            if yPos < 0: #if wall\n",
    "                yPos = 0\n",
    "                \n",
    "        \n",
    "        #update bumpers:\n",
    "        if xPos == 0:\n",
    "            bumpers[\"north\"] = True\n",
    "        else:\n",
    "            bumpers[\"north\"] = False\n",
    "        if xPos == (n-1):\n",
    "            bumpers[\"south\"] = True\n",
    "        else:\n",
    "            bumpers[\"south\"] = False\n",
    "        if yPos == 0: \n",
    "            bumpers[\"west\"] = True\n",
    "        else:\n",
    "            bumpers[\"west\"] = False\n",
    "        if yPos == (n-1):\n",
    "            bumpers[\"east\"] = True\n",
    "        else:\n",
    "            bumpers[\"east\"] = False\n",
    "            \n",
    "        #update performance measures\n",
    "        PerformanceMeasure = PerformanceMeasure + 1\n",
    "        #add stopping mechanism to fix performance measure\n",
    "        roomClean = True\n",
    "        for x in myMap:\n",
    "            for i in x:\n",
    "                if i == 0:\n",
    "                    roomClean = False\n",
    "\n",
    "        if roomClean:\n",
    "            print('Performance Measure:', PerformanceMeasure)    \n",
    "            print('Number Cleaned:', num_cleaned)\n",
    "            return PerformanceMeasure\n",
    "        \n",
    "        #End iteration\n",
    "        \n",
    "\n",
    "    print('Performance Measure:', PerformanceMeasure)    \n",
    "    print('Number Cleaned:', num_cleaned)\n",
    "    return PerformanceMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 475\n",
      "Number Cleaned: 100\n"
     ]
    }
   ],
   "source": [
    "#Run the simulation environment:\n",
    "PerformanceMeasure = simulation_environment(simple_randomized_agent, max_steps = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMap #map is fully clean (all 1's)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:  Implement a simple reflex agent [1 Point] \n",
    "\n",
    "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple reflex agent function:\n",
    "\n",
    "def simple_reflex_agent(bumpers, dirty):\n",
    "    #Agent responds to dirty by sucking it up\n",
    "    if dirty:\n",
    "        return \"suck\"\n",
    "    #agent responds to north wall\n",
    "    if bumpers[\"north\"] == True:\n",
    "        newActions = [\"east\", \"west\", \"south\"]\n",
    "        if bumpers[\"east\"] == True or bumpers[\"west\"] == True:\n",
    "            return \"south\"\n",
    "        return random.choice(newActions)\n",
    "    #agent responds to a south wall\n",
    "    if bumpers[\"south\"] == True:\n",
    "        newActions = [\"east\", \"west\", \"north\"]\n",
    "        if bumpers[\"east\"] == True or bumpers[\"west\"] == True:\n",
    "            return \"north\"\n",
    "        return random.choice(newActions)\n",
    "    #agent responds to an east wall\n",
    "    if bumpers[\"east\"] == True:\n",
    "        newActions = [\"north\", \"west\", \"east\"]\n",
    "        if bumpers[\"north\"] == True or bumpers[\"south\"] == True:\n",
    "            return \"west\"\n",
    "        return random.choice(newActions)\n",
    "    #agent responds to a west wall\n",
    "    if bumpers[\"west\"] == True:\n",
    "        newActions = [\"north\", \"south\", \"east\"]\n",
    "        if bumpers[\"north\"] == True or bumpers[\"south\"] == True:\n",
    "            return \"west\"\n",
    "        return random.choice(newActions)\n",
    "    #move in a random direction, don't suck\n",
    "    newActions = [\"east\", \"west\", \"north\", \"south\"]\n",
    "    return random.choice(newActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 251\n",
      "Number Cleaned: 4\n"
     ]
    }
   ],
   "source": [
    "# Testing the simple_reflex_agent:\n",
    "\n",
    "#reintilize the map:\n",
    "n = 5 #size\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "for i in range(n):\n",
    "    myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    \n",
    "myMap\n",
    "\n",
    "PerformanceMeasure = simulation_environment(simple_reflex_agent, max_steps = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement a model-based reflex agent [3 Point]\n",
    "\n",
    "This agent keeps track of the location and remembers where it has cleaned. Assume the agent knows how many squares the room has. It can move to a corner to determin its location and then is able to use more advanced navigation.\n",
    "\n",
    "_Note on implementing the state:_ You can use a global variable. In Python, you have to use the keyword `global` in your function for this to work (see: https://www.programiz.com/python-programming/global-keyword). Alternatively, you can define a class for your agent with a member variable for the state and a function for the agent program (see: https://www.w3schools.com/python/python_classes.asp). \n",
    "\n",
    "Describe how you define the __agent state__ and how your agent works before implementing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "A Model-based reflex agent maintains an internal state which keeps track of aspects that cannot currently be observed in the environment. This record is then referenced to help the agent make decisions based on the state of the environment. An example of a model-based reflex agent would be the vacuum cleaner remembering where it has cleaned previously. \n",
    "\n",
    "Therefore, an <b>Agent State</b> must be implemented; the Agent State tracks/updates the environment’s current state. In this case, the agent state will keep track of visited/cleaned locations. For this Agent State implementation, a <i>global list of pairs</i> will track all locations visited. A set is particularly useful because it will allow no duplicate elements, meaning it provides additional checking to make sure no location is visited multiple times. The overall agent state’s purpose is to track where the vacuum is visited.\n",
    "\n",
    "In terms of the vacuum movement, the vacuum will move horizontally in one direction until a bumper gets triggered. Next, the bumper will move north or south, and then continue to move horizontally in the other direction until a bumper gets triggered. Moving in this pattern will produce an optimal grid like movement of the vacuum. \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "visitedSpaces =  [ (0,0) ] #remeber where it has cleaned\n",
    "\n",
    "def modelBased_reflex_agent(bumpers, dirty, verbose = True):    \n",
    "    #if current space is dirty, suck it up\n",
    "    if dirty:\n",
    "        return \"suck\"\n",
    "    #if first movement, move East initially\n",
    "    if len(visitedSpaces) == 1:\n",
    "        myPair = (0,1)\n",
    "        visitedSpaces.append(myPair)\n",
    "        return \"east\"\n",
    "    #if east or west bumpers is activated, and current postion has not been visited, move south  \n",
    "    if (bumpers[\"east\"] == True or bumpers[\"west\"] == True):\n",
    "        currPos = visitedSpaces[len(visitedSpaces)  - 1]\n",
    "        if bumpers[\"east\"] == True: \n",
    "            testPosition = (currPos[0], currPos[1] - 1)\n",
    "            if testPosition in visitedSpaces:\n",
    "                finalPos = (currPos[0] + 1, currPos[1])\n",
    "                visitedSpaces.append(finalPos)\n",
    "                return \"south\"\n",
    "            else:\n",
    "                finalPos = (currPos[0], currPos[1] - 1)\n",
    "                visitedSpaces.append(finalPos)\n",
    "                return \"west\"\n",
    "        if bumpers[\"west\"] == True:\n",
    "            testPosition = (currPos[0], currPos[1] + 1)\n",
    "            if testPosition in visitedSpaces:\n",
    "                finalPos = (currPos[0] + 1, currPos[1])\n",
    "                visitedSpaces.append(finalPos)\n",
    "                return \"south\"\n",
    "            else:\n",
    "                finalPos = (currPos[0], currPos[1] + 1)\n",
    "                visitedSpaces.append(finalPos)\n",
    "                return \"east\"\n",
    "         \n",
    "        \n",
    "    currPos = visitedSpaces[len(visitedSpaces)  - 1]\n",
    "    prevPos = visitedSpaces[len(visitedSpaces)  - 2]\n",
    "    #if current xPos is greater than last x Pos, continue to move East\n",
    "    if currPos[1] > prevPos[1]:\n",
    "        finalPos = (currPos[0], currPos[1] + 1)\n",
    "        visitedSpaces.append(finalPos)\n",
    "        return \"east\"\n",
    "    else:\n",
    "        #move west \n",
    "        finalPos = (currPos[0], currPos[1] - 1)\n",
    "        visitedSpaces.append(finalPos)\n",
    "        return \"west\"\n",
    "        \n",
    "    newPos = (currPos[0] + 1, currPos[1])\n",
    "    visitedSpaces.append(newPos)\n",
    "    return \"south\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 28\n",
      "Number Cleaned: 4\n"
     ]
    }
   ],
   "source": [
    "#reintilze the map\n",
    "n = 5 #size\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "for i in range(n):\n",
    "    myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    \n",
    "myMap\n",
    "#Test the model based agent\n",
    "PerformanceMeasure = simulation_environment(modelBased_reflex_agent, max_steps = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Simulation study [3 Points]\n",
    "\n",
    "Compare the performance of the agents using different size environments. E.g., $5 \\times 5$, $10 \\times 10$ and\n",
    "$100 \\times 100$. Use at least 100 random runs for each. Present the results in a suitable format (tables, graphs) and discuss the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Simple Randomized agent trials and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 277\n",
      "Number Cleaned: 59\n",
      "Performance Measure: 557\n",
      "Number Cleaned: 106\n",
      "Performance Measure: 253\n",
      "Number Cleaned: 54\n",
      "Performance Measure: 366\n",
      "Number Cleaned: 75\n",
      "Performance Measure: 274\n",
      "Number Cleaned: 46\n",
      "Performance Measure: 617\n",
      "Number Cleaned: 139\n",
      "Performance Measure: 328\n",
      "Number Cleaned: 62\n",
      "Performance Measure: 528\n",
      "Number Cleaned: 96\n",
      "Performance Measure: 999\n",
      "Number Cleaned: 188\n",
      "Performance Measure: 265\n",
      "Number Cleaned: 59\n",
      "Performance Measure: 196\n",
      "Number Cleaned: 43\n",
      "Performance Measure: 272\n",
      "Number Cleaned: 56\n",
      "Performance Measure: 280\n",
      "Number Cleaned: 51\n",
      "Performance Measure: 664\n",
      "Number Cleaned: 143\n",
      "Performance Measure: 823\n",
      "Number Cleaned: 148\n",
      "Performance Measure: 435\n",
      "Number Cleaned: 99\n",
      "Performance Measure: 350\n",
      "Number Cleaned: 73\n",
      "Performance Measure: 343\n",
      "Number Cleaned: 74\n",
      "Performance Measure: 279\n",
      "Number Cleaned: 59\n",
      "Performance Measure: 125\n",
      "Number Cleaned: 25\n",
      "Performance Measure: 1078\n",
      "Number Cleaned: 219\n",
      "Performance Measure: 558\n",
      "Number Cleaned: 109\n",
      "Performance Measure: 218\n",
      "Number Cleaned: 55\n",
      "Performance Measure: 194\n",
      "Number Cleaned: 41\n",
      "Performance Measure: 529\n",
      "Number Cleaned: 105\n",
      "Performance Measure: 678\n",
      "Number Cleaned: 122\n",
      "Performance Measure: 254\n",
      "Number Cleaned: 64\n",
      "Performance Measure: 788\n",
      "Number Cleaned: 149\n",
      "Performance Measure: 953\n",
      "Number Cleaned: 172\n",
      "Performance Measure: 478\n",
      "Number Cleaned: 99\n",
      "Performance Measure: 275\n",
      "Number Cleaned: 54\n",
      "Performance Measure: 433\n",
      "Number Cleaned: 94\n",
      "Performance Measure: 437\n",
      "Number Cleaned: 88\n",
      "Performance Measure: 344\n",
      "Number Cleaned: 75\n",
      "Performance Measure: 217\n",
      "Number Cleaned: 45\n",
      "Performance Measure: 1262\n",
      "Number Cleaned: 274\n",
      "Performance Measure: 206\n",
      "Number Cleaned: 30\n",
      "Performance Measure: 563\n",
      "Number Cleaned: 105\n",
      "Performance Measure: 490\n",
      "Number Cleaned: 97\n",
      "Performance Measure: 425\n",
      "Number Cleaned: 94\n",
      "Performance Measure: 183\n",
      "Number Cleaned: 34\n",
      "Performance Measure: 416\n",
      "Number Cleaned: 87\n",
      "Performance Measure: 390\n",
      "Number Cleaned: 66\n",
      "Performance Measure: 485\n",
      "Number Cleaned: 94\n",
      "Performance Measure: 192\n",
      "Number Cleaned: 43\n",
      "Performance Measure: 491\n",
      "Number Cleaned: 110\n",
      "Performance Measure: 293\n",
      "Number Cleaned: 60\n",
      "Performance Measure: 446\n",
      "Number Cleaned: 94\n",
      "Performance Measure: 218\n",
      "Number Cleaned: 44\n",
      "Performance Measure: 316\n",
      "Number Cleaned: 60\n",
      "Performance Measure: 4274\n",
      "Number Cleaned: 894\n",
      "Performance Measure: 3071\n",
      "Number Cleaned: 674\n",
      "Performance Measure: 1889\n",
      "Number Cleaned: 376\n",
      "Performance Measure: 6383\n",
      "Number Cleaned: 1280\n",
      "Performance Measure: 6391\n",
      "Number Cleaned: 1265\n",
      "Performance Measure: 4106\n",
      "Number Cleaned: 853\n",
      "Performance Measure: 1179\n",
      "Number Cleaned: 262\n",
      "Performance Measure: 1507\n",
      "Number Cleaned: 299\n",
      "Performance Measure: 2130\n",
      "Number Cleaned: 423\n",
      "Performance Measure: 1383\n",
      "Number Cleaned: 280\n",
      "Performance Measure: 1713\n",
      "Number Cleaned: 345\n",
      "Performance Measure: 1684\n",
      "Number Cleaned: 301\n",
      "Performance Measure: 1740\n",
      "Number Cleaned: 385\n",
      "Performance Measure: 1252\n",
      "Number Cleaned: 255\n",
      "Performance Measure: 3040\n",
      "Number Cleaned: 606\n",
      "Performance Measure: 3694\n",
      "Number Cleaned: 753\n",
      "Performance Measure: 2354\n",
      "Number Cleaned: 485\n",
      "Performance Measure: 2168\n",
      "Number Cleaned: 418\n",
      "Performance Measure: 2028\n",
      "Number Cleaned: 403\n",
      "Performance Measure: 2580\n",
      "Number Cleaned: 536\n",
      "Performance Measure: 2950\n",
      "Number Cleaned: 607\n",
      "Performance Measure: 5394\n",
      "Number Cleaned: 1093\n",
      "Performance Measure: 2959\n",
      "Number Cleaned: 586\n",
      "Performance Measure: 1070\n",
      "Number Cleaned: 215\n",
      "Performance Measure: 2938\n",
      "Number Cleaned: 577\n",
      "Performance Measure: 1486\n",
      "Number Cleaned: 292\n",
      "Performance Measure: 1268\n",
      "Number Cleaned: 262\n",
      "Performance Measure: 2043\n",
      "Number Cleaned: 401\n",
      "Performance Measure: 2572\n",
      "Number Cleaned: 541\n",
      "Performance Measure: 3991\n",
      "Number Cleaned: 781\n",
      "Performance Measure: 2257\n",
      "Number Cleaned: 482\n",
      "Performance Measure: 1546\n",
      "Number Cleaned: 322\n",
      "Performance Measure: 1240\n",
      "Number Cleaned: 273\n",
      "Performance Measure: 1477\n",
      "Number Cleaned: 314\n",
      "Performance Measure: 1426\n",
      "Number Cleaned: 279\n",
      "Performance Measure: 2904\n",
      "Number Cleaned: 623\n",
      "Performance Measure: 1362\n",
      "Number Cleaned: 287\n",
      "Performance Measure: 1859\n",
      "Number Cleaned: 354\n",
      "Performance Measure: 959\n",
      "Number Cleaned: 198\n",
      "Performance Measure: 1964\n",
      "Number Cleaned: 391\n",
      "Performance Measure: 2874\n",
      "Number Cleaned: 605\n",
      "Performance Measure: 2374\n",
      "Number Cleaned: 498\n",
      "Performance Measure: 2856\n",
      "Number Cleaned: 528\n",
      "Performance Measure: 1576\n",
      "Number Cleaned: 310\n",
      "Performance Measure: 1308\n",
      "Number Cleaned: 251\n",
      "Performance Measure: 5223\n",
      "Number Cleaned: 1006\n",
      "Performance Measure: 1661\n",
      "Number Cleaned: 340\n",
      "Performance Measure: 904\n",
      "Number Cleaned: 191\n",
      "Performance Measure: 4818\n",
      "Number Cleaned: 975\n",
      "Performance Measure: 1610\n",
      "Number Cleaned: 341\n",
      "Performance Measure: 30000\n",
      "Number Cleaned: 6060\n"
     ]
    }
   ],
   "source": [
    "#100 trials for a simple_randomized_agent:\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "randomizedAgent_result_five = []\n",
    "randomizedAgent_result_ten = []\n",
    "randomizedAgent_result_hundred = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    n = 5 #size\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_randomized_agent, max_steps = 2000)\n",
    "    randomizedAgent_result_five.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(50):\n",
    "    n = 10 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_randomized_agent, max_steps = 10000)\n",
    "    randomizedAgent_result_ten.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(5):\n",
    "    n = 100 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_randomized_agent, max_steps = 30000)\n",
    "    randomizedAgent_result_hundred.append(PerformanceMeasure)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'random Agent performance measure 100x100'}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(25, 7))\n",
    "                \n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"random Agent performance measure 5x5\")\n",
    "sns.boxplot(randomizedAgent_result_five)\n",
    "plt.xlim(0, 1250)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"random Agent performance measure 10x10\")\n",
    "sns.boxplot(randomizedAgent_result_ten)\n",
    "plt.xlim(0, 5000)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"random Agent performance measure 100x100\")\n",
    "sns.boxplot(randomizedAgent_result_hundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "random Agent performance measure 5x5:\n",
      "Minimum = 125\n",
      "Maximum = 1262\n",
      "Range = 1137\n",
      "Varience = 60551.62760000001\n",
      "Standard Deviation = 246.0724031662226\n",
      "------------------------------------\n",
      "random Agent performance measure 10x10:\n",
      "Minimum = 904\n",
      "Maximum = 6391\n",
      "Range = 5487\n",
      "Varience = 1817852.5699999996\n",
      "Standard Deviation = 1348.277630905445\n",
      "------------------------------------\n",
      "random Agent performance measure 100x100:\n",
      "Minimum = 30000\n",
      "Maximum = 30000\n",
      "Range = 0\n",
      "Varience = 0.0\n",
      "Standard Deviation = 0.0\n"
     ]
    }
   ],
   "source": [
    "printStats = True\n",
    "if printStats:\n",
    "    #\n",
    "    Mymin = np.amin(randomizedAgent_result_five) \n",
    "    Mymax = np.amax(randomizedAgent_result_five) \n",
    "    Myrange = np.ptp(randomizedAgent_result_five) \n",
    "    Myvarience = np.var(randomizedAgent_result_five) \n",
    "    mysd = np.std(randomizedAgent_result_five) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 5x5:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) \n",
    "\n",
    "    Mymin = np.amin(randomizedAgent_result_ten) \n",
    "    Mymax = np.amax(randomizedAgent_result_ten) \n",
    "    Myrange = np.ptp(randomizedAgent_result_ten) \n",
    "    Myvarience = np.var(randomizedAgent_result_ten) \n",
    "    mysd = np.std(randomizedAgent_result_ten) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 10x10:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd)  \n",
    "\n",
    "    Mymin = np.amin(randomizedAgent_result_hundred) \n",
    "    Mymax = np.amax(randomizedAgent_result_hundred) \n",
    "    Myrange = np.ptp(randomizedAgent_result_hundred) \n",
    "    Myvarience = np.var(randomizedAgent_result_hundred) \n",
    "    mysd = np.std(randomizedAgent_result_hundred) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 100x100:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Simple Randomized agent results serve as a baseline for comparison for the more advanced agents. The Simple Randomized agent does not behave rationally, instead it randomly chooses to move in one direction or suck up the dirt. This means the range of the results/performance measure varies greatly because the outcome is dependent on chance. \n",
    "<br><br>\n",
    "For smaller rooms such as 5x5, the simple randomized agent performs reasonably considering the agent is guided by random chance. However, the worst-case scenarios for cleaning the room are very large because there might be a square that takes an agent awhile for cleaning up. Therefore, the variance, standard deviation, and range are all very high for this 5x5 board. These same discrepancies can be applied to the 10x10 board for this agent. The range, standard deviation, and variance are all even larger due to being dependent on random chance. \n",
    "<br><br>\n",
    "When dealing with larger rooms such as 100x100, it is almost infeasible for the Simple Randomized agent to clean the entire room. The reason for this being, with random chance it could take an extremely long time for the robot to randomly clean every single square on the grid. The performance measure was always equal to the number of max-steps, which is why the third box-plot is just a line. Only a few trails were run with the large room due to these discrepancies and long run time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr> <h4> Simple Reflexive agent trials and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 144\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 126\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 62\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 176\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 224\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 60\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 57\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 56\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 161\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 97\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 142\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 334\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 215\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 85\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 101\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 157\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 22\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 72\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 152\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 93\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 141\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 81\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 132\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 182\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 92\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 96\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 66\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 221\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 485\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 270\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 64\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 122\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 96\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 20\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 127\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 134\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 609\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 70\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 98\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 237\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 26\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 102\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 57\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 83\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 94\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 41\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 365\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 108\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 138\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 109\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 99\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 30\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 150\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 358\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 383\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 12\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 71\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 85\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 214\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 93\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 182\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 59\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 114\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 141\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 51\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 97\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 84\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 1009\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 81\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 138\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 53\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 143\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 242\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 52\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 264\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 52\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 308\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 129\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 263\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 153\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 208\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 29\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 167\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 241\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 88\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 77\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 116\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 107\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 153\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 59\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 32\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 74\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 68\n",
      "Number Cleaned: 2\n",
      "Performance Measure: 85\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 133\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 177\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 97\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 86\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 69\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 445\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 913\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 616\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 1551\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 496\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 117\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 945\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1628\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 481\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 641\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 931\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 2690\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 773\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 233\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1183\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 631\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 883\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 973\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 694\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1450\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1128\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 637\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 571\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 490\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1640\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1658\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 778\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 159\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 197\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 516\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 608\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1648\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1037\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 899\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 883\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1004\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 336\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 803\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 400\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 640\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 862\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 797\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 797\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 515\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1417\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 918\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1137\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 393\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 7\n",
      "Performance Measure: 224\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 935\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 325\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 869\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 2172\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 608\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 820\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1028\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 227\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 628\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 671\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 994\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 829\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 892\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 948\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 361\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 957\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 352\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1371\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 776\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 532\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 983\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 533\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1056\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1009\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 244\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 493\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 648\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 831\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 578\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 770\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 208\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 547\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 858\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1613\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 548\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 641\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 743\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 675\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 659\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1152\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 2280\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 371\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 924\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1745\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 246\n",
      "Number Cleaned: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 457\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 724\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 2328\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 814\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 379\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 953\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 30000\n",
      "Number Cleaned: 54\n",
      "Performance Measure: 30000\n",
      "Number Cleaned: 63\n",
      "Performance Measure: 30000\n",
      "Number Cleaned: 43\n"
     ]
    }
   ],
   "source": [
    "#100 trials for a simple_reflex_agent:\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "simpleReflex_result_five = []\n",
    "simpleReflex_result_ten = []\n",
    "simpleReflex_result_hundred = []\n",
    "\n",
    "j = 0\n",
    "for j in range(0, 100):\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    n = 5 #size\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_reflex_agent, max_steps = 2000)\n",
    "    simpleReflex_result_five.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(0,100):\n",
    "    n = 10 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_reflex_agent, max_steps = 10000)\n",
    "    simpleReflex_result_ten.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(0,3):\n",
    "    n = 100 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(simple_reflex_agent, max_steps = 30000)\n",
    "    simpleReflex_result_hundred.append(PerformanceMeasure)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'random Agent performance measure 100x100'}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the results:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(25, 7))\n",
    "                \n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"random Agent performance measure 5x5\")\n",
    "sns.boxplot(simpleReflex_result_five)\n",
    "plt.xlim(0, 350)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"random Agent performance measure 10x10\")\n",
    "sns.boxplot(simpleReflex_result_ten)\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"random Agent performance measure 100x100\")\n",
    "sns.boxplot(simpleReflex_result_hundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "random Agent performance measure 5x5:\n",
      "Minimum = 12\n",
      "Maximum = 1009\n",
      "Range = 997\n",
      "Varience = 18044.717099999998\n",
      "Standard Deviation = 134.33062606866685\n",
      "------------------------------------\n",
      "random Agent performance measure 10x10:\n",
      "Minimum = 117\n",
      "Maximum = 2690\n",
      "Range = 2573\n",
      "Varience = 231148.53240000003\n",
      "Standard Deviation = 480.7790889795437\n",
      "------------------------------------\n",
      "random Agent performance measure 100x100:\n",
      "Minimum = 30000\n",
      "Maximum = 30000\n",
      "Range = 0\n",
      "Varience = 0.0\n",
      "Standard Deviation = 0.0\n"
     ]
    }
   ],
   "source": [
    "printStats = True\n",
    "if printStats:\n",
    "    #simpleReflex_result_five stats\n",
    "    Mymin = np.amin(simpleReflex_result_five) \n",
    "    Mymax = np.amax(simpleReflex_result_five) \n",
    "    Myrange = np.ptp(simpleReflex_result_five) \n",
    "    Myvarience = np.var(simpleReflex_result_five) \n",
    "    mysd = np.std(simpleReflex_result_five) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 5x5:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) \n",
    "\n",
    "    ##simpleReflex_result_ten stats\n",
    "    Mymin = np.amin(simpleReflex_result_ten) \n",
    "    Mymax = np.amax(simpleReflex_result_ten) \n",
    "    Myrange = np.ptp(simpleReflex_result_ten) \n",
    "    Myvarience = np.var(simpleReflex_result_ten) \n",
    "    mysd = np.std(simpleReflex_result_ten) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 10x10:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd)  \n",
    "\n",
    "    Mymin = np.amin(simpleReflex_result_hundred) \n",
    "    Mymax = np.amax(simpleReflex_result_hundred) \n",
    "    Myrange = np.ptp(simpleReflex_result_hundred) \n",
    "    Myvarience = np.var(simpleReflex_result_hundred) \n",
    "    mysd = np.std(simpleReflex_result_hundred) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 100x100:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple reflexive agent does not maintain an internal state of the environment but simply reacts to its sensors: cleaning when commanded by the dirty sensor, not moving in direction of an active sensor, etc. Therefore, we can expect an increase in performance across the board- specifically with the smaller room sizes.\n",
    "<br><br>\n",
    "Like the simple random agent, the simple reflexive agent had large range, standard deviation, and variance for both the 5x5 and 10x10 room sizes. However, the performance measure for the simple reflexive agent for both the 5x5 and 10x10 room sizes is much better. The performance measure median for the simple random agent is 400 versus 100 for the simple reflexive agent (5x5 room size). For the 10x10 room size, the median performance measure was ~750 for the simple reflexive agent versus ~2000 for the simple random agent. Just using the sensors greatly improves the performance of the agent. \n",
    "<br><br>\n",
    "However, when examining the larger room sizes (100x100), the agent still failed to clean the room. Like before, The performance measure was always equal to the number of max-steps, which is why the third box-plot is just a line. The agent needs a way to maintain an internal state and keep track of where it has been, it is very hard to clean a large room with a random navigation system. Only a few trails were run with the large room due to these discrepancies and long run time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <br> <h4> Model-based reflex agent trials and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Measure: 26\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 21\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 26\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 29\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 18\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 28\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 27\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 29\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 17\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 19\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 24\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 22\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 19\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 19\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 27\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 27\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 24\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 2\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 24\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 24\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 25\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 24\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 20\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 22\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 2\n",
      "Performance Measure: 500\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 22\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 17\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 16\n",
      "Number Cleaned: 4\n",
      "Performance Measure: 28\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 27\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 23\n",
      "Number Cleaned: 5\n",
      "Performance Measure: 20\n",
      "Number Cleaned: 3\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 7\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 100\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 7\n",
      "Performance Measure: 89\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 89\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 84\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 98\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 102\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 99\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 109\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 100\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 104\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 86\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 82\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 86\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 91\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 92\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 106\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 79\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 109\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 7\n",
      "Performance Measure: 90\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 90\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 87\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 96\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 107\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 86\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 96\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 107\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 90\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 91\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 1000\n",
      "Number Cleaned: 8\n",
      "Performance Measure: 93\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 97\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 91\n",
      "Number Cleaned: 10\n",
      "Performance Measure: 95\n",
      "Number Cleaned: 9\n",
      "Performance Measure: 9941\n",
      "Number Cleaned: 98\n",
      "Performance Measure: 10049\n",
      "Number Cleaned: 100\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 97\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 99\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 97\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 98\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 98\n",
      "Performance Measure: 9814\n",
      "Number Cleaned: 100\n",
      "Performance Measure: 15000\n",
      "Number Cleaned: 99\n",
      "Performance Measure: 9972\n",
      "Number Cleaned: 100\n"
     ]
    }
   ],
   "source": [
    "#100 trials for a modelBased_reflexice_agent:\n",
    "n=5\n",
    "myMap = np.ones((n,n), dtype = int) #map of size n\n",
    "modelBased_result_five = []\n",
    "modelBased_result_ten = []\n",
    "modelBased_result_hundred = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    n = 5 #size\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, 5), random.randint(0, 5)] = 0\n",
    "    PerformanceMeasure = simulation_environment(modelBased_reflex_agent, max_steps = 500)\n",
    "    modelBased_result_five.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(50):\n",
    "    n = 10 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(modelBased_reflex_agent, max_steps = 1000)\n",
    "    modelBased_result_ten.append(PerformanceMeasure)\n",
    "    \n",
    "for i in range(10):\n",
    "    n = 100 #size\n",
    "    myMap = np.ones((n,n), dtype = int)\n",
    "    for i in range(n):\n",
    "        myMap[random.randint(0, n), random.randint(0, n)] = 0\n",
    "    PerformanceMeasure = simulation_environment(modelBased_reflex_agent, max_steps = 15000)\n",
    "    modelBased_result_hundred.append(PerformanceMeasure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'model based performance measure 100x100'}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYQAAAGrCAYAAABwnpOyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm30lEQVR4nO3de7htdVkv8O8LmzsiCGi6UbeKadYxJI9aXvLkJTXUUvOSmpxuj3kkSistO0WpT3fT6BwtL1leSruTee2CncxKIFAJyK1BsLmIIImyg4Df+WOMxR57sfbaa7HXZa71+3yeZz5rzjHmHGP83jnmfOf6zjnHrNZaAAAAAADY/PZb7w0AAAAAAGBtCIQBAAAAADohEAYAAAAA6IRAGAAAAACgEwJhAAAAAIBOCIQBAAAAADohEN7EqurtVfWaJV734qp6/L4uZ7VU1WlV9c41XN8PVtVVVfXlqjp6rdYLwOakJ+/T+vRkAFaMnrxP69OTYZMQCMM8VXVAktcleWJr7fDW2jXrvU3su/EF203ji5e50/5LvO3FVbVzcrsPr/b2AqAnb1ZV9eyq+vuquqGqzlxg/glVdfY4/+yqOmGJy717VZ1RVZdXVauqbfPmH1RVb6uqL1XVlVX1shUZEEAH9OTNaV97clX9yNhT/2PssQfN8nrZRSAME1W1Jcndkhyc5Pw7cPuqKo+rVbYPdf6l8cXL3OmWZdz2qZPbPfEOrBuAZdCTN4Y7WOdrk7w+yS8ssLwDk/xZkncmOSrJ7yT5s3H63tya5INJnrmH+acluX+Seyf5H0l+vKqetMxtB+iOnrwxrHVPrqpvTfLKJI9Lsi3JfZP87Iyvl5EH5DobP3n4Y1X1yar6SlW9taruVlUfqKrrq+ovq+qoyfWfVlXnV9V1VXVmVX3NZN5Dquqc8XbvyfBkPV3XSVV17njbv6+qBy9jU4+pqo+My/5oVd17stw3VNWl46ctzq6qR0/mPayqzhrnXVVVr5vMe8S4HddV1XlV9djJvPuM67m+qj6S5JhFavjYqrqsqn6yqr4w1vT5k/kHVdWvVNW/j9vwpqo6ZN5tX1FVVyZ5R5KLxpteV1V/PV7vm6rqE+O7T5+oqm+aLP/MqnptVX0syQ1J7lvDp1JeUlWfGcfw6qq6X1V9fKzFeydPZkdV1fuq6uqq+uJ4/rh5y391VX1sXNaHq+qYyfxHTep4aVWdvLdxL1DDk8fl/9q4nM+NYz55XObnq+pFS6zp3sZz8rj866vq3+buq5r3daeq2jbWccsidX7guF9eW1UXVdWz97SfLKaqnjNu0xHj5SfX8G7jsXdkecDGVHqynqwnr0lPbq39ZWvtvUkuX2D2Y5NsSfL61tqNrbVfT1JJvmVc9/ur6lcn2/aeqnrbuNyrWmv/N8kn9rDq707y6tbaF1trFyR5c5KT97SdwPopPVlP1pNnvicneVGSt7bWzm+tfTHJqzP21fF+vbaqThwv32PcDx+7mutlGVprTut4SnJxkn/I8G7b1iSfT3JOkockOSjJXyf5mfG6X53kK0mekOSAJD+eZHuSA8fTJUl+ZJz3rCT/leQ1421PHJf98CT7Z3gAXZzkoMl2PH4P2/j2JNcnecy4TW9I8neT+S9IcnSGB+zLk1yZ5OBx3seTvHA8f3iSR4zntya5JslTMrwx8YTx8rGT271uXN9jxvW/cw/b99gkN0+u/81jnR4wzn99kjOS3CXJnZL8eZKfn3fbXxxve0iGd5haki3jde6S5ItJXjiO8Xnj5aPH+Wcm+fckXzvOP2C8/RlJjhin35jkrzK8c3XnJP+S5EXj7Y/O8EmWQ8ft+4MkfzoZ35lJPjve/4eMl39hnHevsTbPG9d7dJIT9jbuBWp48liH/5lh/3jNOKb/M9blieN6Dl9CTfc4niSHJfnS5L65e5KvHc+fNr2PF7gf5tf5zkkuHbd5S4Z9/Atzy9vDfnzteDo7yTPnzX/XeJ2jMzSlk+Y9Tq9KcnWSDyf5+vV+7nByclr5U/RkPVlPXpOePFnu9yU5c960H0nygXnT3pfk5eP5r8rw+PmWJM9P8rkkd5p3/S3j9m6bTDtqnHa3ybRnJfnUej/3ODk53f4UPVlP1pM3Qk8+L8lzJvOOGbdtbh/4/iQXjGP+UJJfWYv1Oi3xeXa9N6D3U4YG8/zJ5T9K8sbJ5VMmTxL/O8l7J/P2S7Ijw5P1YzKEWDWZ//fZ1ejemOETEdN1X5TkmyfbsVij+/3J5cOT3JLknnu4/hczBmZJ/jbDR/ePmXedVyR5x7xpH8rQgO+V4Un3sMm8d2fvjW56/feO9aoMTe9+k3nfmOTfJre9KWNjHqdty+5PsC9M8k/z1vnxJCeP589M8nPz5rckj5xcPjvJKyaXfzXDu10LjeeEJF+cXD4zyU9NLr8kyQfH8z+R5E8WWMai417g+icn+czk8n/L7f9pumbctuUu+7bxZGh012VohIfMu95p2Xuj+7nJ/Ock+X/zlvGbGV8YLrAdJ2bXC7KnZGjc0/voyAyN9FNJfnPebR+Z4UXGoWPNr0xy5J4e105OThvzFD15Ok1PbnryIvfDbnXOMnvy5DoL/RP4vzPZx8dp70py2uTyMzL8s/uFJI9aYLkLBcL3HKdN968nJLl4sW10cnJan1P05Ok0PbnpyYvcD7vVOWvYkzME8k+azJsL/bdNpp2R4X/sT2Z8o2Ut1uu095NDRsyGqybndy5w+fDx/D0yvLuZJGmt3ZrhxfDWcd6ONj4aRpdMzt87ycvHrzlcV1XXZXhhfI8lbuOlk/V+OcOnLO+RJFX18qq6YPyayHUZ3pGa+6rG92Z4x+7C8SskJ0225zvnbc+jMrwTdo8MT4xf2cNYFrLQ9e+R5NgMId7Zk/V8cJw+5+rW2n8usuzd6j5Z/tbJ5Utze0u6X6vq0Kr6zaq6pKq+lOHFwZG1+w+eXTk5f0N27RP3zPBkON9Sxr237U1rbaFtXnTZi41nvI+ek+TFSa6oqr+oqgcusk3zTet87yQPn7cPPT/DJ4dup7V2Tmvtmtbaza2192doKM+YzL8uw7u0X5fhhcj0th9rre1srd3QWvv5DM360QE2Iz1ZT9aTl+YO9+S9+HKGT45NHZHhjdw578vwSa2LWmt/t4zlzi1rT8sFZouerCfryUuzXj15/vy589Pe+uYM/2Of3lq7cQ3Xy14IhDeWyzM8uJMMBwzP8ES3I8kVSbaO0+bca3L+0iSvba0dOTkd2lr7vSWu+56T9R6e4SsQl9dwHKRXJHl2kqNaa0cm+Y8M746ltfaZ1trzktw1w9dN/rCqDhu35x3ztuew1tovjGM5arzeQmNZyELXvzzDJ0d2Zvh6xNx67txaO3xy3emLg4XsVvfJ8ncsYxmLeXmSByR5eGvtiAzvYidjDffi0iT3W2D6UsZ9R+1t2YuOp7X2odbaEzK8qLkwQ4NIhndTD52sZ6GGNa3zpUk+Om8fOry19oNLHEfLpMY1/Grp9yT5vSS/vpzbAl3Sk/dMT96dnrw85yd58LzHz4Oz+48YvTbDV1DvXlXPW8pC23CMwSuSfP1k8tfnDvw4EjBz9OQ905N3pycvz9568vm5fV+9qrV2TXLbY+L1Sd6a5LSqustarJelEQhvLO9N8m1V9biqOiDDE8qNGb7y8vEMXwf5oaraUlXPSPKwyW3fnOTFVfXwGhxWVd9WVXda4rqfUsNB2Q/McMDuf2ytXZrh2Dc3Zzi26paq+ulM3qmpqhdU1bHju7TXjZNvyfBrkU+tqm+tqv2r6uAaDlx/XGvtkiRnJfnZqjqwqh6V5KlL2Ma56z86yUlJ/mBc75uT/FpV3XXcpq01/CrlUr0/yVdX1XeNtX1Okgdl+HTKSrhThsZx3fgE+TPLuO27kjy+qp49btvRVXXCCo17QUtY9h7HU8MPQTxtfFFyY4Z39m4ZZ5+b5DFVda+qunOGr/ks5n0Z7pcXVtUB4+m/1+QHJKaq6llVdXhV7VdVT8xwTK8zxnkHZ9gnfzLDsZa2VtVLxnn3qqpHjvvWwVX1Yxne2f/YkosGbEZ68uL0ZD15sZ68/9h7tyTZb9znDhhnnzluxw/V8OM8Lx2nz/2A0WMy9OrvHk+nV9XWybIPznBcxyQ5aLw853eT/FQNP+zzwAzHNnz7XsYGzD49eXF6sp68Kj05Q1/93qp6UA0/8vhT2b2vviHJ2a2170vyF0netEbrZQkEwhtIa+2iDCHW6RnefXpqkqe21m5qrd2U4evvJ2c4NtFzkvzx5LZnZXjR+xvj/O1Z3q8wvjvDE9a1Sb4hw1cOkuF4Rh9I8q8Zvh7yn9n96wpPSnJ+VX05w5PBc1tr/zk2yadnCOCuHm/zY9m1T35XhgP7Xzuu93f3sn1XjuO6PMOT/4tbaxeO814xjvcfavhqxl9meGduScZ3mU7K8MLimgw/UnBSa+0LS13GXrw+w/Fpv5DhhxM+uIxt+/cMx8N9eYZanZtd75Tt07j3YrFlvz57Hs9+47ZePm7vN2c41lNaax9J8p4MxxY6O3t5IdFauz7DQfyfOy7vyuz60YOFnJrh3errkvxyku9vrZ05zvv5JJe11t7Yhq+xvCDJa6rq/hka9xsz7F87MuzTT/buI/RNT16Unqwn760nvzDDP8VvzHAIpp0ZPwk1Pn6+PUPYe12Gb+98e2vtpqo6IsP+99LW2o42HC7irUl+u+q2TxHtzK7DQ1w4Xp7zMxm+QnxJko8m+eXW2pLvY2A26cmL0pP15FXpyeP8Dyb5pSR/k2E/vyRj0F1VT8+wn794XM/LkpxYVXOPkVVZL0tXbbdD6cDGU1WPzXCQ9ePWeVMAoGt6MgDMBj0ZWIxPCAMAAAAAdEIgDAAAAADQCYeMAAAAAADohE8IAwAAAAB0YstyrnzMMce0bdu2rdKmANC7s88++wuttWPXezs2Ov0agNWkX68M/RqA1bannr2sQHjbtm0566yzVm6rAGCiqi5Z723YDPRrAFaTfr0y9GsAVtueerZDRgAAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAntqzFSk4//fRs3749O3bsSJJs3bp1LVYLMPOOP/74nHLKKeu9GbAg/ZteeC4GejPX4wGYLTt27MiRRx6Zt7zlLau6njUJhLdv355zP31BkpYkufLGNVktwEzb/4Zr13sTYFH6Nz3wXAz0aK7H33LoXdZ7UwCY2P/6a7Jz585VX8+a/Wc3bTQ7H/iUtVotwMw65ML3r/cmwF7p32x2nouBXt1y6F30doAZc/g571iT9TiGMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJwTCAAAAAACdEAgDAAAAAHRCIAwAAAAA0AmBMAAAAABAJ7asxkJPP/30JMkpp5yyGosH2BT2+88vZceOm9d7M2A3eji98VwMbHR6N8AmcustufHGG1d9NasSCG/fvn01FguwqdSt/5WdO3eu92bAbvRweuO5GNjo9G6ATaS13Hrrrau+GoeMAAAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE5sWY2F7tixIzt37sypp56aJNm+fXv2u6nl1oOPWI3VAQArZNrD9W8AmH3z//9eirkeD0Cf9voJ4ar6gao6q6rOuvrqq9dimwCAZdKvAWD26dcAzIK9fkK4tfZbSX4rSR760Icu6S3ErVu3Jkne8IY3JElOPfXUnP25q+7wRgIAi7sj/Xoh0x6ufwPAylqpfj01///vpdDjAfrmGMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdGLLaiz0+OOPX43FAmwqbb8Dcsghh6z3ZsBu9HB647kY2Oj0boBNpCr77bf6n99dlUD4lFNOWY3FAmwqtx58RLZuvdt6bwbsRg+nN56LgY1O7wbYRPbbPwcddODqr2bV1wAAAAAAwEwQCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ0QCAMAAAAAdEIgDAAAAADQCYEwAAAAAEAnBMIAAAAAAJ3YslYr2v+Ga5O0JMkhF75/rVYLMLOG58W7rfdmwKL0bzY7z8VAr/a/4Vq9HWDW3HJzkgNXfTVrEggff/zxSZIdO3YkSbZu9aIbILnbbc+PMIv0b/rguRjoj+c9gNm0Y8fNOfLII1d9PWsSCJ9yyilrsRoAYAXp3wCwOenxAH1zDGEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKATAmEAAAAAgE4IhAEAAAAAOiEQBgAAAADohEAYAAAAAKAT1Vpb+pWrrk9y0eptzoZzTJIvrPdGzBD1uD012Z163J6a7O4BrbU7rfdGbHSbrF9vtsfIZhqPscymzTSWZHONZzONRb9eAVV1dZJL1nETNtM+uRrUZ3Hqszj1WZz6LG4l63Pv1tqx8yduWeZCLmqtPXSFNmjDq6qz1GMX9bg9Ndmdetyemuyuqs5a723YJDZNv95sj5HNNB5jmU2baSzJ5hrPZhvLem/DZrDQP+hraTPtk6tBfRanPotTn8Wpz+LWoj4OGQEAAAAA0AmBMAAAAABAJ5YbCP/WqmzFxqUeu1OP21OT3anH7anJ7tRjZWymOm6msSSbazzGMps201iSzTUeY2HWuB8Xpz6LU5/Fqc/i1Gdxq16fZf2oHAAAAAAAG5dDRgAAAAAAdEIgDAAAAADQiSUFwlX1pKq6qKq2V9UrV3ujZkVVva2qPl9Vn55Mu0tVfaSqPjP+PWoy7yfGGl1UVd+6Plu9eqrqnlX1N1V1QVWdX1WnjtO7rElVHVxV/1RV5431+Nlxepf1mFNV+1fVP1fV+8bLvdfj4qr6VFWdW1VnjdO6rUlVHVlVf1hVF47PJd/Ycz1W2kbs14v0ltOqasf42Dm3qp4yuc3M7heb5TFfVQ+Y1P7cqvpSVf3wRrpfVup1XFV9w3ifbq+qX6+qmpGx/PL4XPrJqvqTqjpynL6tqnZO7qM3bYCxLHu/muGxvGcyjour6txx+qzfLyv2On8WxtOb1X6+q6qDxn17e1X9Y1VtW9MB7qM91Oc7x3391qp66Lzrd1Of5fSXcV43tUn2WJ9Xj7U5t6o+XFX3mMzrvj6TeT9aVa2qjplM674+tYKvefa5Pq21RU9J9k/y2ST3TXJgkvOSPGhvt9sMpySPSXJikk9Ppv1SkleO51+Z5BfH8w8aa3NQkvuMNdt/vcewwvW4e5ITx/N3SvKv47i7rEmSSnL4eP6AJP+Y5BG91mNSl5cleXeS942Xe6/HxUmOmTet25ok+Z0k3zeePzDJkT3XY4VruyH79SK95bQkP7rA9Wd6v9iMj/lx37oyyb030v2SFXodl+Sfknxjhr7/gSRPnpGxPDHJlvH8L07Gsm16vXnLmdWxLHu/mtWxzJv/q0l+eoPcLyv2On8WxtPbabWf75K8JMmbxvPPTfKe9R7zCtTna5I8IMmZSR46md5VffZQmz31l65qs0h9jpic/6HJ+NRn1/R7JvlQkksyvi5Wn9umnZYVes2zr/VZyieEH5Zke2vtc621m5L8fpKnL+F2G15r7W+TXDtv8tMzBBoZ/377ZPrvt9ZubK39W5LtGWq3abTWrmitnTOevz7JBUm2ptOatMGXx4sHjKeWTuuRJFV1XJJvS/KWyeRu67GILmtSVUdkaIpvTZLW2k2ttevSaT1WwYbs14v0lj3ZiPvFRt/HH5fks621Sxa5zsyNZSVex1XV3TP84/fxNrza/t3JbdbMQmNprX24tXbzePEfkhy32DJmeSyL2HD3y5zx0zvPTvJ7iy1jhsayIq/zZ2U8vVmD57vpsv4wyePmPqG2EezhOfSC1tpFC1y9q/oss790VZtkj/X50uTiYRkygER9pn4tyY9nV20S9dmbNa/PUgLhrUkunVy+LIv/o7bZ3a21dkUyvHBKctdxeld1Gj+K/pAMn4rttiY1HB7h3CSfT/KR1lrX9Ujy+gxP/LdOpvVcj2Rogh+uqrOr6gfGab3W5L5Jrk7y2zUcVuQtVXVY+q3HStvw9ZrXW5LkpeNX8t5Wu77qOuvj3IyP+edm91BrI94vc5Z7X2wdz8+fPmu+J8MnRubcZ3ye/WhVPXqcNutjWc5+NetjSZJHJ7mqtfaZybQNcb/s4+v8mRtPx1byvrvtNmNQ+B9Jjl61LV9f6rO7aX9Rm1FVvbaqLk3y/CQ/PU5WnyRV9bQkO1pr582bpT67rNRrnn2qz1IC4YXS5bbAtN51U6eqOjzJHyX54Xnvjt3uqgtM21Q1aa3d0lo7IcO7pg+rqq9b5Oqbuh5VdVKSz7fWzl7qTRaYtmnqMfHI1tqJSZ6c5H9V1WMWue5mr8mWDF+ZeWNr7SFJvpLhK4x7stnrsdI2dL0W6C1vTHK/JCckuSLDV6+T2R/npnrMV9WBSZ6W5A/GSRv1ftmbPW3/zI+rql6V5OYk7xonXZHkXuPz7MuSvHv8hsYsj2W5+9Usj2XO87L7Gykb4n5Zgdf5MzUeFnRH7rue7lf1GS3QX9Rm1Fp7VWvtnhlq89Jxcvf1qapDk7wqu0Ly3WYvMK2r+oxW8jXPPtVnKYHwZRmO/zHnuCSXL3UFm9BV40e2577i9flxehd1qqoDMrxIfFdr7Y/HyV3XJEna8LX3M5M8Kf3W45FJnlZVF2f4qvq3VNU70289kiSttcvHv59P8icZvkLda00uS3LZ+En6ZPhay4nptx4rbcPWa6He0lq7anzT7dYkb86uww/M9Dg34WP+yUnOaa1dlWzc+2ViuffFZdn9UAwzNa6qelGSk5I8f/waYcavGl4znj87wzHovjozPJY7sF/N7FiSpKq2JHlGkvfMTdsI98sKvc6fmfGwovfdbbcZ9+87Z+lfg95o1CcL95eozULeneSZ43n1GYLO+yQ5b8wFjktyTlV9VdQnyYq/5tmn+iwlEP5EkvtX1X3GT4k8N8kZS13BJnRGkheN51+U5M8m0587/srffZLcP8OBnzeN8Vgkb01yQWvtdZNZXdakqo6tXb/ofUiSxye5MJ3Wo7X2E62141pr2zI8T/x1a+0F6bQeSVJVh1XVnebOZ/iBhk+n05q01q5McmlVPWCc9Lgk/5JO67EKNmS/3lNvmfsndvQdGR47yQzvF5v0Mb/bpxw34v0yz7Lui/Fr1tdX1SPGffW7J7dZV1X1pCSvSPK01toNk+nHVtX+4/n7ZhjL52Z8LMvar2Z5LKPHJ7mwtXbbVzxn/X5Zqdf5szIekqzsfTdd1rMyvM7f6J/S25Pu67On/hK1SZJU1f0nF5+WIQNI1CettU+11u7aWts25gKXZfjB0iujPklW/DXPvtWnLe2X8Z6S4ZdmP5vkVUu5zWY4ZfgH6Iok/5VhR/7eDMfj+Ksknxn/3mVy/VeNNboom/DXdJM8KsPHzz+Z5Nzx9JRea5LkwUn+eazHp7PrV6S7rMe82jw2yft6r0eGY+aeN57On3v+7LwmJyQ5a3zc/GmSo3quxyrUd8P160V6yzuSfGqcfkaSu8/6frHZHvNJDk1yTZI7T6ZtmPslK/Q6LslDM/T5zyb5jSQ1I2PZnuG4cXOPm7lfmX7muP+dl+ScJE/dAGNZ9n41q2MZp789yYvnXXfW75cVe50/C+Pp7bTaz3dJDs5w6KDtGd7su+96j3kF6vMd4/kbk1yV5EM91mcPtVmwv/RWm0Xq80fjWD+Z5M+TbFWf3fvgZP7FSY5Rn9V5zbOv9ZlbCAAAAAAAm9xSDhkBAAAAAMAmIBAGAAAAAOiEQBgAAAAAoBMCYQAAAACATgiEAQAAAAA6IRAGAAAAAOiEQBgAAAAAoBP/H+prt3QMnDtAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1800x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the results:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplots(figsize=(25, 7))\n",
    "                \n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"model based performance measure 5x5\")\n",
    "sns.boxplot(modelBased_result_five)\n",
    "plt.xlim(0, 600)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"model based performance measure 10x10\")\n",
    "sns.boxplot(modelBased_result_ten)\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"model based performance measure 100x100\")\n",
    "sns.boxplot(modelBased_result_hundred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "random Agent performance measure 5x5:\n",
      "Minimum = 16\n",
      "Maximum = 500\n",
      "Range = 484\n",
      "Varience = 47766.8276\n",
      "Standard Deviation = 218.5562344111922\n",
      "------------------------------------\n",
      "random Agent performance measure 10x10:\n",
      "Minimum = 79\n",
      "Maximum = 1000\n",
      "Range = 921\n",
      "Varience = 188992.2836\n",
      "Standard Deviation = 434.7324275919614\n",
      "------------------------------------\n",
      "random Agent performance measure 100x100:\n",
      "Minimum = 9814\n",
      "Maximum = 15000\n",
      "Range = 5186\n",
      "Varience = 6138024.4399999995\n",
      "Standard Deviation = 2477.5036710366344\n"
     ]
    }
   ],
   "source": [
    "printStats = True\n",
    "if printStats:\n",
    "    #simpleReflex_result_five stats\n",
    "    Mymin = np.amin(modelBased_result_five) \n",
    "    Mymax = np.amax(modelBased_result_five) \n",
    "    Myrange = np.ptp(modelBased_result_five) \n",
    "    Myvarience = np.var(modelBased_result_five) \n",
    "    mysd = np.std(modelBased_result_five) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 5x5:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) \n",
    "\n",
    "    ##simpleReflex_result_ten stats\n",
    "    Mymin = np.amin(modelBased_result_ten) \n",
    "    Mymax = np.amax(modelBased_result_ten) \n",
    "    Myrange = np.ptp(modelBased_result_ten) \n",
    "    Myvarience = np.var(modelBased_result_ten) \n",
    "    mysd = np.std(modelBased_result_ten) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 10x10:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd)  \n",
    "\n",
    "    Mymin = np.amin(modelBased_result_hundred) \n",
    "    Mymax = np.amax(modelBased_result_hundred) \n",
    "    Myrange = np.ptp(modelBased_result_hundred) \n",
    "    Myvarience = np.var(modelBased_result_hundred) \n",
    "    mysd = np.std(modelBased_result_hundred) \n",
    "\n",
    "    print(\"------------------------------------\") \n",
    "    print(\"random Agent performance measure 100x100:\") \n",
    "    print(\"Minimum =\", Mymin) \n",
    "    print(\"Maximum =\", Mymax) \n",
    "    print(\"Range =\", Myrange) \n",
    "    print(\"Varience =\", Myvarience) \n",
    "    print(\"Standard Deviation =\", mysd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-based agent maintains an internal state and keeps track of locations where it has been. These qualities allow for an optimized and rational performance of the agent. There were some discrepancies/outliers where the agent would get stuck in a corner and require the max_steps to stop the iteration.\n",
    "<br> <br>\n",
    "Excluding these outliers, in the 5x5 room, the performance measure was always very similar and optimal (common values include 18, 17, 19, 24). The difference in these common values is due to the random locations of the initial dirt. The same near optimal performance measures can be seen in the 10x10 room distribution and boxplot. \n",
    "<br> <br>\n",
    "When looking at the 100x100 room, we can see the benefits of the model-based agent versus the simple reflexive agent and random agent. Where the other agents would have taken forever, the model-based agent is able to clean the 100x100 room with a performance measure of approximately 10,000. The internal state and systematic navigation allows the model-based agent to perform well. Since the trials take a very long time, the normal 100 trials were shortened. \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Robustness of the agent implementations [1 Point] \n",
    "\n",
    "Describe how your agent implementations will perform \n",
    "\n",
    "* if it is put into a rectangular room with unknown size, \n",
    "* if the cleaning area can have an iregular shape (e.g., a hallway connecting two rooms), or \n",
    "* if the room contains obstacles (i.e., squares that it cannot pass through and trigger the bumper sensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <br>\n",
    "1) In my model based-reflexive agent, a rectangular room of unknown size will not affect the agent’s rationality and it will still behave optimally. My model based-reflexive agent has not context of the environment size/shape. Instead, it iterates horizontally and cleans from left to right, and left to right once reaching the other side. To accomplish this the bump sensors and a list of visited spaces are used. Meaning, the size of the rectangular room does not matter and the model-based reflexive agent will stay behave properly/optimally for this environment. \n",
    "<br> <br>\n",
    "2) If the cleaning area was an irregular shape, the irregular shape would have a great impact on the performance of my model-based agent. My model-based agent keeps track of what spaces are visited and will not move back to a space it has already traversed. This feature could cause the agent/vacuum to get infinitely stuck and not be able to clean the entire room For example, consider an environment with an irregular corner with a 1x1 opening. If the agent/vacuum went into this corner it would not be able to get out because it had already visited the spot to get in. Overall, the irregular shape could cause the model-based agent to infinitely loop forever and not be able to properly clean the room. <br> <br>\n",
    "\n",
    "3) Like the irregular shape, the obstacles could cause the model-based agent to get stuck, become unusable, and unable to clean the room. Since my agent iterates horizontally from right to left and left to right, if it hit a wall it would start to iterate back the other way. When it traveled back past the wall there is a chance it would miss some dirty spaces. For example, If the environment had a barrier wall protruding into the room, the agent would clean till it hit the wall and then move down. However, when the agent came back past the wall, it would have no way to check the other side of the wall, since it only moves left right and down. Overall a protruding wall or an obstacle could cause the model-based agent to not perform fully/properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus tasks [+1 Point]\n",
    "\n",
    "Change your simulation environment tor run experiments for the following problems:\n",
    "\n",
    "* __Obstacles:__ Add random obstacle squares that also trigger the bumper sensor. The agent does not know where the obstacles are. Observe how this changes the performance of the three implementations.\n",
    "* __Unknown environment with obstacles:__ Implement an agent for an environment where the agent does not know how large the environment is (we assume it is rectangular), where it starts or where the obstacles are. An option would be to always move to the closest unchecked/uncleaned square.\n",
    "* __Utility-based agent:__ Change the environment, so each square has a fixed probability of getting dirty again. We assume the agent has learned this information over time. For the implementation, we give this information to the agent as a 2-dimensional array of probabilities  Cleaning one dirty square produces a utility of 1. Implement a utility-based agent that maximizes the expected utility over one full charge which lasts for 10000 time steps. This is very tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and discussion goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
